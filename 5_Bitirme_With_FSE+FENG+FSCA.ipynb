{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olaXI9R9H0nM",
        "outputId": "45b14328-71e4-4b09-8d64-25c780728b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.77736959        nan 0.77551879        nan 0.77366764]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier\n",
            "Best Score: 0.863561\n",
            "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300, 'subsample': 1.0}\n",
            "\n",
            "RandomForestClassifier\n",
            "Best Score: 0.815178\n",
            "Best Parameters: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "KNeighborsClassifier\n",
            "Best Score: 0.815177\n",
            "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
            "\n",
            "DecisionTreeClassifier\n",
            "Best Score: 0.793497\n",
            "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "\n",
            "LinearSVC\n",
            "Best Score: 0.777634\n",
            "Best Parameters: {'C': 0.1}\n",
            "\n",
            "LogisticRegression\n",
            "Best Score: 0.777370\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/bitirme/new_out2.csv')\n",
        "\n",
        "# Veri setini sınıflandırma için hazırlama\n",
        "popularity_threshold = dataframe['popularity'].median()\n",
        "dataframe['popularity'] = dataframe['popularity'].apply(lambda x: 1 if x > 50 else 0)\n",
        "\n",
        "# X ve y ayırma\n",
        "X = dataframe.drop('popularity', axis=1)\n",
        "y = dataframe['popularity']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Eğitim ve test veri setlerini oluşturma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# K-fold çapraz doğrulama için ayarlama\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Sınıflandırma modelleri ve hiperparametre aralıkları\n",
        "models = [\n",
        "    (RandomForestClassifier(), {'n_estimators': [100, 200, 300], 'max_depth': [5, 8, 10], 'min_samples_split': [2, 5, 10], 'max_features': ['sqrt', 'log2']}),\n",
        "    (DecisionTreeClassifier(), {'max_depth': [5, 8, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 3, 5], 'max_features': [None, 'sqrt']}),\n",
        "    (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}),\n",
        "    (LogisticRegression(), {'C': [0.1, 0.5, 1.0], 'penalty': ['l1', 'l2']}),\n",
        "    (XGBClassifier(), {'learning_rate': [0.01, 0.1], 'n_estimators': [100, 200, 300], 'max_depth': [5, 8, 10], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0]}),\n",
        "    (LinearSVC(), {'C': [0.1, 0.5, 1.0]})\n",
        "]\n",
        "\n",
        "# Performans ölçümlerini saklamak için bir sözlük oluşturma\n",
        "performance_scores = {}\n",
        "\n",
        "# Modelleri eğitme ve performans ölçümü (K-fold çapraz doğrulama)\n",
        "for model, params in models:\n",
        "    grid_search = GridSearchCV(model, params, cv=kfold, scoring='accuracy')\n",
        "    grid_search.fit(X_scaled, y)\n",
        "\n",
        "    best_score = grid_search.best_score_\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    performance_scores[model.__class__.__name__] = {\n",
        "        'best_score': best_score,\n",
        "        'best_params': best_params\n",
        "    }\n",
        "\n",
        "# Performans skorlarına göre sıralama\n",
        "sorted_scores = sorted(performance_scores.items(), key=lambda x: x[1]['best_score'], reverse=True)\n",
        "\n",
        "# Sıralanmış performans skorlarını yazdırma\n",
        "for model_name, scores in sorted_scores:\n",
        "    print(f\"{model_name}\")\n",
        "    print(f\"Best Score: {scores['best_score']:.6f}\")\n",
        "    print(f\"Best Parameters: {scores['best_params']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcMVfGi-L6Zf",
        "outputId": "ca2eb100-0560-437f-cc36-68a26bffe069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (XGBClassifier): 0.878468\n",
            "\n",
            "Accuracy (RandomForestClassifier): 0.850727\n",
            "\n",
            "Accuracy (KNeighborsClassifier): 0.828269\n",
            "\n",
            "Accuracy (DecisionTreeClassifier): 0.792602\n",
            "\n",
            "Accuracy (LinearSVC): 0.775429\n",
            "\n",
            "Accuracy (LogisticRegression): 0.772787\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the dataset\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/bitirme/new_out2.csv')\n",
        "popularity_threshold = dataframe['popularity'].median()\n",
        "dataframe['popularity'] = dataframe['popularity'].apply(lambda x: 1 if x > 50 else 0)\n",
        "X = dataframe.drop('popularity', axis=1)\n",
        "y = dataframe['popularity']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the classifiers with the best parameters\n",
        "classifiers = [\n",
        "    XGBClassifier(colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0),\n",
        "    RandomForestClassifier(max_depth=18, max_features='log2', min_samples_split=3, n_estimators=250),\n",
        "    KNeighborsClassifier(metric='euclidean', n_neighbors=10, weights='distance'),\n",
        "    DecisionTreeClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2),\n",
        "    LinearSVC(C=0.1),\n",
        "    LogisticRegression(C=0.1, penalty='l2')\n",
        "]\n",
        "\n",
        "# Calculate accuracy for each classifier\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train_scaled, y_train)\n",
        "    y_pred = classifier.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy ({classifier.__class__.__name__}): {accuracy:.6f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib5lYsBl6uIk",
        "outputId": "cce930c5-7435-4560-e063-1fa23c544070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (XGBClassifier): 0.952149\n",
            "\n",
            "Accuracy (RandomForestClassifier): 0.883728\n",
            "\n",
            "Accuracy (KNeighborsClassifier): 0.835044\n",
            "\n",
            "Accuracy (DecisionTreeClassifier): 0.764781\n",
            "\n",
            "Accuracy (LinearSVC): 0.760482\n",
            "\n",
            "Accuracy (LogisticRegression): 0.760570\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the dataset\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/bitirme/new_dataset2.csv')\n",
        "popularity_threshold = dataframe['popularity'].median()\n",
        "dataframe['popularity'] = dataframe['popularity'].apply(lambda x: 1 if x > 50 else 0)\n",
        "X = dataframe.drop('popularity', axis=1)\n",
        "y = dataframe['popularity']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the classifiers with the best parameters\n",
        "classifiers = [\n",
        "    XGBClassifier(colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0),\n",
        "    RandomForestClassifier(max_depth=18, max_features='log2', min_samples_split=3, n_estimators=250),\n",
        "    KNeighborsClassifier(metric='euclidean', n_neighbors=10, weights='distance'),\n",
        "    DecisionTreeClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2),\n",
        "    LinearSVC(C=0.1),\n",
        "    LogisticRegression(C=0.1, penalty='l2')\n",
        "]\n",
        "\n",
        "# Calculate accuracy for each classifier\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train_scaled, y_train)\n",
        "    y_pred = classifier.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy ({classifier.__class__.__name__}): {accuracy:.6f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o8Jn4ic7uC_",
        "outputId": "03f5e5fb-9048-400c-c377-1cdc4e725c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (XGBClassifier): 0.964893\n",
            "\n",
            "Accuracy (RandomForestClassifier): 0.897757\n",
            "\n",
            "Accuracy (KNeighborsClassifier): 0.878639\n",
            "\n",
            "Accuracy (DecisionTreeClassifier): 0.882441\n",
            "\n",
            "Accuracy (LinearSVC): 0.882287\n",
            "\n",
            "Accuracy (LogisticRegression): 0.882424\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the dataset\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/bitirme/new_tracks2.csv')\n",
        "popularity_threshold = dataframe['popularity'].median()\n",
        "dataframe['popularity'] = dataframe['popularity'].apply(lambda x: 1 if x > 50 else 0)\n",
        "X = dataframe.drop('popularity', axis=1)\n",
        "y = dataframe['popularity']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the classifiers with the best parameters\n",
        "classifiers = [\n",
        "    XGBClassifier(colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0),\n",
        "    RandomForestClassifier(max_depth=18, max_features='log2', min_samples_split=3, n_estimators=250),\n",
        "    KNeighborsClassifier(metric='euclidean', n_neighbors=10, weights='distance'),\n",
        "    DecisionTreeClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2),\n",
        "    LinearSVC(C=0.1),\n",
        "    LogisticRegression(C=0.1, penalty='l2')\n",
        "]\n",
        "\n",
        "# Calculate accuracy for each classifier\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train_scaled, y_train)\n",
        "    y_pred = classifier.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy ({classifier.__class__.__name__}): {accuracy:.6f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_x, data_y):\n",
        "    k_fold = KFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "    predicted_targets = np.array([])\n",
        "    actual_targets = np.array([])\n",
        "\n",
        "    TN = np.array([])\n",
        "    TP = np.array([])\n",
        "    FP = np.array([])\n",
        "    FN = np.array([])\n",
        "    F1_Score = np.array([])\n",
        "    Recal_Score = np.array([])\n",
        "\n",
        "    Train_ACC =np.array([])\n",
        "    Test_ACC = np.array([])\n",
        "\n",
        "    Precision_Score = np.array([])\n",
        "    Train_Times = np.array([])\n",
        "    Test_Times = np.array([])\n",
        "\n",
        "    AUCS = np.array([])\n",
        "\n",
        "    false_positive_rates = np.array([])\n",
        "    true_positive_rates = np.array([])\n",
        "    FPR1 = np.array([])\n",
        "    FPR2 = np.array([])\n",
        "    FPR3 = np.array([])\n",
        "\n",
        "    TPR1 = np.array([])\n",
        "    TPR2 = np.array([])\n",
        "    TPR3 = np.array([])\n",
        "\n",
        "    A_class_0_precision =  np.array([])\n",
        "    A_class_0_recall =  np.array([])\n",
        "    A_class_0_f1_score =  np.array([])\n",
        "    A_class_0_support =  np.array([])\n",
        "    A_class_1_precision =  np.array([])\n",
        "    A_class_1_recall =  np.array([])\n",
        "    A_class_1_f1_score =  np.array([])\n",
        "    A_class_1_support =  np.array([])\n",
        "    A_clf_report_acc = np.array([])\n",
        "    A_class_macro_avg_precision =  np.array([])\n",
        "    A_class_macro_avg_recall =  np.array([])\n",
        "    A_class_macro_avg_f1_score =  np.array([])\n",
        "    A_class_macro_avg_support =  np.array([])\n",
        "    A_class_weighted_avg_precision =  np.array([])\n",
        "    A_class_weighted_avg_recall =  np.array([])\n",
        "    A_class_weighted_avg_f1_score =  np.array([])\n",
        "    A_class_weighted_avg_support =  np.array([])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    test_x = []\n",
        "    test_y = []\n",
        "\n",
        "\n",
        "\n",
        "    for train_ix, test_ix in k_fold.split(data_x):\n",
        "        train_x, train_y, test_x, test_y = data_x.iloc[train_ix], data_y.iloc[train_ix], data_x.iloc[test_ix], data_y.iloc[test_ix]\n",
        "\n",
        "        # Fit the classifier\n",
        "        t0 = time.time()\n",
        "        classifier = model.fit(train_x, train_y)\n",
        "        train_time = time.time() - t0\n",
        "\n",
        "        # Predict the labels of the test set samples\n",
        "        t0 = time.time()\n",
        "        predicted_labels = classifier.predict(test_x)\n",
        "        test_time = time.time() - t0\n",
        "        predicted_targets = np.append(predicted_targets, predicted_labels)\n",
        "        actual_targets = np.append(actual_targets, test_y)\n",
        "\n",
        "        target_names = ['class_0','class_1']\n",
        "        clf_rept = classification_report(predicted_labels, test_y, output_dict=True)\n",
        "        print(classification_report(predicted_labels, test_y))\n",
        "\n",
        "        class_0_precision =  clf_rept['0']['precision']\n",
        "        class_0_recall =  clf_rept['0']['recall']\n",
        "        class_0_f1_score =  clf_rept['0']['f1-score']\n",
        "        class_0_support =  clf_rept['0']['support']\n",
        "\n",
        "        class_1_precision =  clf_rept['1']['precision']\n",
        "        class_1_recall =  clf_rept['1']['recall']\n",
        "        class_1_f1_score =  clf_rept['1']['f1-score']\n",
        "        class_1_support =  clf_rept['1']['support']\n",
        "\n",
        "        clf_report_acc = clf_rept['accuracy']\n",
        "\n",
        "        class_macro_avg_precision =  clf_rept['macro avg']['precision']\n",
        "        class_macro_avg_recall =  clf_rept['macro avg']['recall']\n",
        "        class_macro_avg_f1_score =  clf_rept['macro avg']['f1-score']\n",
        "        class_macro_avg_support =  clf_rept['macro avg']['support']\n",
        "\n",
        "        class_weighted_avg_precision =  clf_rept['weighted avg']['precision']\n",
        "        class_weighted_avg_recall =  clf_rept['weighted avg']['recall']\n",
        "        class_weighted_avg_f1_score =  clf_rept['weighted avg']['f1-score']\n",
        "        class_weighted_avg_support =  clf_rept['weighted avg']['support']\n",
        "\n",
        "        #add to\n",
        "\n",
        "        A_class_0_precision = np.append(A_class_0_precision,class_0_precision)\n",
        "        A_class_0_recall = np.append(A_class_0_recall,class_0_recall)\n",
        "        A_class_0_f1_score = np.append(A_class_0_f1_score,class_0_f1_score)\n",
        "        A_class_0_support = np.append(A_class_0_support,class_0_support)\n",
        "\n",
        "        A_class_1_precision = np.append(A_class_1_precision,class_1_precision)\n",
        "        A_class_1_recall = np.append(A_class_1_recall,class_1_recall)\n",
        "        A_class_1_f1_score = np.append(A_class_1_f1_score,class_1_f1_score)\n",
        "        A_class_1_support = np.append(A_class_1_support,class_1_support)\n",
        "\n",
        "        A_clf_report_acc = np.append(A_clf_report_acc,clf_report_acc)\n",
        "\n",
        "        A_class_macro_avg_precision = np.append(A_class_macro_avg_precision,class_macro_avg_precision)\n",
        "        A_class_macro_avg_recall = np.append(A_class_macro_avg_recall,class_macro_avg_recall)\n",
        "        A_class_macro_avg_f1_score = np.append(A_class_macro_avg_f1_score,class_macro_avg_f1_score)\n",
        "        A_class_macro_avg_support = np.append(A_class_macro_avg_support,class_macro_avg_support)\n",
        "\n",
        "\n",
        "        A_class_weighted_avg_precision = np.append(A_class_weighted_avg_precision,class_weighted_avg_precision)\n",
        "        A_class_weighted_avg_recall = np.append(A_class_weighted_avg_recall,class_weighted_avg_recall)\n",
        "        A_class_weighted_avg_f1_score = np.append(A_class_weighted_avg_f1_score,class_weighted_avg_f1_score)\n",
        "        A_class_weighted_avg_support = np.append(A_class_weighted_avg_support,class_weighted_avg_support)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(predicted_labels, test_y).ravel()\n",
        "\n",
        "        f1 = f1_score(test_y, predicted_labels,average='micro')\n",
        "\n",
        "        recall = recall_score(test_y, predicted_labels)\n",
        "\n",
        "        test_Acc = accuracy_score(test_y, predicted_labels)\n",
        "        precisionScore = precision_score(test_y, predicted_labels)\n",
        "        #train acc\n",
        "        trainPred = classifier.predict(train_x)\n",
        "        train_acc = accuracy_score(trainPred, train_y)\n",
        "\n",
        "        auc = metrics.roc_auc_score(test_y, predicted_labels)\n",
        "\n",
        "\n",
        "        false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(test_y, predicted_labels)\n",
        "\n",
        "\n",
        "        print('false_positive_rate len: ',len(false_positive_rate))\n",
        "        print(\"k fold true_positive_rate:\", true_positive_rate)\n",
        "        print(\"k fold false_positive_rate:\", false_positive_rate)\n",
        "\n",
        "        fpr1 = false_positive_rate[0]\n",
        "\n",
        "\n",
        "        fpr2 = false_positive_rate[1]\n",
        "        try:\n",
        "          fpr3 = false_positive_rate[2]\n",
        "          FPR3 = np.append(FPR3,fpr3)\n",
        "        except:\n",
        "          print(1)\n",
        "\n",
        "        #print(fpr1,fpr2,fpr3)\n",
        "\n",
        "\n",
        "        tpr1 = true_positive_rate[0]\n",
        "        tpr2 = true_positive_rate[1]\n",
        "        try:\n",
        "          tpr3 = true_positive_rate[2]\n",
        "          TPR3 = np.append(TPR3,tpr3)\n",
        "        except:\n",
        "          print(1)\n",
        "\n",
        "\n",
        "        FPR1 = np.append(FPR1,fpr1)\n",
        "        FPR2 = np.append(FPR2,fpr2)\n",
        "\n",
        "\n",
        "        TPR1 = np.append(TPR1,tpr1)\n",
        "        TPR2 = np.append(TPR2,tpr2)\n",
        "\n",
        "\n",
        "\n",
        "        F1_Score = np.append(F1_Score, f1)\n",
        "        Recal_Score = np.append(Recal_Score,recall)\n",
        "        Train_ACC = np.append(Train_ACC,train_acc)\n",
        "        Test_ACC = np.append(Test_ACC,test_Acc)\n",
        "        Precision_Score = np.append(Precision_Score,precisionScore)\n",
        "        TN = np.append(TN, tn)\n",
        "        TP = np.append(TP, tp)\n",
        "        FN = np.append(FN, fn)\n",
        "        FP = np.append(FP, fp)\n",
        "\n",
        "\n",
        "        AUCS = np.append(AUCS,auc)\n",
        "        false_positive_rates = np.append(false_positive_rates,false_positive_rate)\n",
        "        true_positive_rates = np.append(true_positive_rates,true_positive_rate)\n",
        "\n",
        "\n",
        "    TP = (np.mean(TP))\n",
        "    TN = (np.mean(TN))\n",
        "    FP = (np.mean(FP))\n",
        "    FN = (np.mean(FN))\n",
        "    print('test: ',Test_ACC)\n",
        "    print('F1_Score: ',F1_Score)\n",
        "    print('Recal_Score: ',Recal_Score)\n",
        "    print('Train_ACC: ',Train_ACC)\n",
        "    print('Precision_Score: ',Precision_Score)\n",
        "    F1_Score = (np.mean(F1_Score))\n",
        "    Recal_Score = (np.mean(Recal_Score))\n",
        "    Train_ACC = (np.mean(Train_ACC))\n",
        "\n",
        "    Test_ACC = (np.mean(Test_ACC))\n",
        "    Precision_Score = np.mean(Precision_Score)\n",
        "\n",
        "    AUCS = np.mean(AUCS)\n",
        "    FPR1 = np.mean(FPR1)\n",
        "    FPR2 = np.mean(FPR2)\n",
        "\n",
        "    TPR1 = np.mean(TPR1)\n",
        "    TPR2 = np.mean(TPR2)\n",
        "\n",
        "    A_class_0_precision =  np.mean(A_class_0_precision)\n",
        "    A_class_0_recall =  np.mean(A_class_0_recall)\n",
        "    A_class_0_f1_score =  np.mean(A_class_0_f1_score)\n",
        "    A_class_0_support =  np.mean(A_class_0_support)\n",
        "    A_class_1_precision =  np.mean(A_class_1_precision)\n",
        "    A_class_1_recall =  np.mean(A_class_1_recall)\n",
        "    A_class_1_f1_score =  np.mean(A_class_1_f1_score)\n",
        "    A_class_1_support =  np.mean(A_class_1_support)\n",
        "    A_clf_report_acc = np.mean(A_clf_report_acc)\n",
        "    A_class_macro_avg_precision =  np.mean(A_class_macro_avg_precision)\n",
        "    A_class_macro_avg_recall =  np.mean(A_class_macro_avg_recall)\n",
        "    A_class_macro_avg_f1_score =  np.mean(A_class_macro_avg_f1_score)\n",
        "    A_class_macro_avg_support =  np.mean(A_class_macro_avg_support)\n",
        "    A_class_weighted_avg_precision =  np.mean(A_class_weighted_avg_precision)\n",
        "    A_class_weighted_avg_recall =  np.mean(A_class_weighted_avg_recall)\n",
        "    A_class_weighted_avg_f1_score =  np.mean(A_class_weighted_avg_f1_score)\n",
        "    A_class_weighted_avg_support =  np.mean(A_class_weighted_avg_support)\n",
        "\n",
        "    try:\n",
        "\n",
        "      TPR3 = np.mean(TPR3)\n",
        "      FPR3 = np.mean(FPR3)\n",
        "      false_positive_rates = np.array([FPR1,FPR2,FPR3])\n",
        "      true_positive_rates = np.array([TPR1,TPR2,TPR3])\n",
        "\n",
        "    except:\n",
        "      print(1)\n",
        "      false_positive_rates = np.array([FPR1,FPR2])\n",
        "      true_positive_rates = np.array([TPR1,TPR2])\n",
        "\n",
        "\n",
        "\n",
        "    return TN, TP, FN, FP, F1_Score, Recal_Score, Train_ACC, Test_ACC, Precision_Score, AUCS, false_positive_rates, true_positive_rates,A_class_0_precision,A_class_0_recall ,A_class_0_f1_score,A_class_0_support ,A_class_1_precision,A_class_1_recall ,A_class_1_f1_score,A_class_1_support,A_clf_report_acc ,A_class_macro_avg_precision,A_class_macro_avg_recall,A_class_macro_avg_f1_score,A_class_macro_avg_support,A_class_weighted_avg_precision,A_class_weighted_avg_recall,A_class_weighted_avg_f1_score,A_class_weighted_avg_support\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YFnwLcxA2tDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,roc_curve,classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "# Özellikler\n",
        "features = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\",\n",
        "            \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\", 'loudness',]\n",
        "\n",
        "# Veri setini yükleme\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/bitirme/dataset.csv')\n",
        "\n",
        "# Boş değerleri içeren satırları silme\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "dataframe['popularity'] = dataframe['popularity'].apply(lambda x: 1 if x > 50 else 0)\n",
        "\n",
        "# X ve y ayırma\n",
        "X = dataframe[features]\n",
        "y = dataframe['popularity']\n",
        "\n",
        "\n",
        "\n",
        "# Sınıflandırma modelleri\n",
        "models = [\n",
        "    RandomForestClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    KNeighborsClassifier(),\n",
        "    LogisticRegression(),\n",
        "    XGBClassifier(),\n",
        "    LinearSVC()\n",
        "]\n",
        "\n",
        "# Calculate accuracy for each classifier using k-fold cross-validation\n",
        "for classifier in models:\n",
        "    TN, TP, FN, FP, F1_Score, Recal_Score, Train_ACC, Test_ACC, Precision_Score, AUCS, false_positive_rates, true_positive_rates,A_class_0_precision,A_class_0_recall ,A_class_0_f1_score,A_class_0_support ,A_class_1_precision,A_class_1_recall ,A_class_1_f1_score,A_class_1_support,A_clf_report_acc ,A_class_macro_avg_precision,A_class_macro_avg_recall,A_class_macro_avg_f1_score,A_class_macro_avg_support,A_class_weighted_avg_precision,A_class_weighted_avg_recall,A_class_weighted_avg_f1_score,A_class_weighted_avg_support  = evaluate_model(classifier, X, y)\n",
        "    print(str(classifier))\n",
        "    print(\"mean Test_ACC: \",Test_ACC.mean())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omPwReaf2mw1",
        "outputId": "f1328d27-1700-4527-8206-edd366f00c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91     19886\n",
            "           1       0.47      0.91      0.62      2914\n",
            "\n",
            "    accuracy                           0.86     22800\n",
            "   macro avg       0.73      0.88      0.77     22800\n",
            "weighted avg       0.92      0.86      0.88     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.47123776 1.        ]\n",
            "k fold false_positive_rate: [0.       0.015595 1.      ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91     19879\n",
            "           1       0.47      0.90      0.62      2921\n",
            "\n",
            "    accuracy                           0.86     22800\n",
            "   macro avg       0.73      0.88      0.77     22800\n",
            "weighted avg       0.92      0.86      0.88     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.47303877 1.        ]\n",
            "k fold false_positive_rate: [0.         0.01727036 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91     19929\n",
            "           1       0.46      0.88      0.60      2871\n",
            "\n",
            "    accuracy                           0.85     22800\n",
            "   macro avg       0.72      0.87      0.76     22800\n",
            "weighted avg       0.91      0.85      0.87     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.45925791 1.        ]\n",
            "k fold false_positive_rate: [0.         0.01999769 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91     19871\n",
            "           1       0.47      0.91      0.62      2929\n",
            "\n",
            "    accuracy                           0.86     22800\n",
            "   macro avg       0.73      0.88      0.77     22800\n",
            "weighted avg       0.92      0.86      0.87     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.46978558 1.        ]\n",
            "k fold false_positive_rate: [0.        0.0162033 1.       ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.86      0.92     19887\n",
            "           1       0.48      0.90      0.62      2912\n",
            "\n",
            "    accuracy                           0.86     22799\n",
            "   macro avg       0.73      0.88      0.77     22799\n",
            "weighted avg       0.92      0.86      0.88     22799\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.47760102 1.        ]\n",
            "k fold false_positive_rate: [0.         0.01731102 1.        ]\n",
            "test:  [0.85802632 0.85877193 0.85442982 0.85657895 0.86152901]\n",
            "F1_Score:  [0.85802632 0.85877193 0.85442982 0.85657895 0.86152901]\n",
            "Recal_Score:  [0.47123776 0.47303877 0.45925791 0.46978558 0.47760102]\n",
            "Train_ACC:  [0.9926315  0.99287273 0.99273018 0.99265343 0.99252193]\n",
            "Precision_Score:  [0.9080302  0.89798014 0.8794845  0.90508706 0.89697802]\n",
            "RandomForestClassifier()\n",
            "mean Test_ACC:  0.8578672063948634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86     16829\n",
            "           1       0.60      0.57      0.58      5971\n",
            "\n",
            "    accuracy                           0.79     22800\n",
            "   macro avg       0.73      0.72      0.72     22800\n",
            "weighted avg       0.78      0.79      0.79     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.60124666 1.        ]\n",
            "k fold false_positive_rate: [0.         0.15100378 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86     16878\n",
            "           1       0.60      0.56      0.58      5922\n",
            "\n",
            "    accuracy                           0.79     22800\n",
            "   macro avg       0.73      0.72      0.72     22800\n",
            "weighted avg       0.79      0.79      0.79     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.60198377 1.        ]\n",
            "k fold false_positive_rate: [0.         0.14975369 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86     16893\n",
            "           1       0.60      0.55      0.57      5907\n",
            "\n",
            "    accuracy                           0.79     22800\n",
            "   macro avg       0.72      0.71      0.72     22800\n",
            "weighted avg       0.78      0.79      0.78     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.59621681 1.        ]\n",
            "k fold false_positive_rate: [0.         0.15194775 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86     16772\n",
            "           1       0.60      0.56      0.58      6028\n",
            "\n",
            "    accuracy                           0.79     22800\n",
            "   macro avg       0.72      0.72      0.72     22800\n",
            "weighted avg       0.78      0.79      0.78     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.60251639 1.        ]\n",
            "k fold false_positive_rate: [0.         0.15317363 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86     16836\n",
            "           1       0.61      0.55      0.58      5963\n",
            "\n",
            "    accuracy                           0.79     22799\n",
            "   macro avg       0.73      0.71      0.72     22799\n",
            "weighted avg       0.78      0.79      0.79     22799\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.60504663 1.        ]\n",
            "k fold false_positive_rate: [0.         0.15314484 1.        ]\n",
            "test:  [0.78798246 0.78986842 0.78732456 0.78635965 0.78885039]\n",
            "F1_Score:  [0.78798246 0.78986842 0.78732456 0.78635965 0.78885039]\n",
            "Recal_Score:  [0.60124666 0.60198377 0.59621681 0.60251639 0.60504663]\n",
            "Train_ACC:  [0.99265343 0.99287273 0.99274115 0.99265343 0.99252193]\n",
            "Precision_Score:  [0.56539943 0.56366093 0.55493482 0.56403451 0.55492202]\n",
            "DecisionTreeClassifier()\n",
            "mean Test_ACC:  0.7880770951788436\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83     19066\n",
            "           1       0.29      0.43      0.34      3734\n",
            "\n",
            "    accuracy                           0.73     22800\n",
            "   macro avg       0.58      0.61      0.59     22800\n",
            "weighted avg       0.78      0.73      0.75     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.28655387 1.        ]\n",
            "k fold false_positive_rate: [0.         0.12365435 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.84     19218\n",
            "           1       0.28      0.44      0.35      3582\n",
            "\n",
            "    accuracy                           0.74     22800\n",
            "   macro avg       0.58      0.62      0.59     22800\n",
            "weighted avg       0.79      0.74      0.76     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.28403968 1.        ]\n",
            "k fold false_positive_rate: [0.         0.11631411 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83     19143\n",
            "           1       0.28      0.43      0.34      3657\n",
            "\n",
            "    accuracy                           0.73     22800\n",
            "   macro avg       0.58      0.61      0.59     22800\n",
            "weighted avg       0.78      0.73      0.75     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.       0.283012 1.      ]\n",
            "k fold false_positive_rate: [0.         0.12143105 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83     19146\n",
            "           1       0.28      0.44      0.34      3654\n",
            "\n",
            "    accuracy                           0.73     22800\n",
            "   macro avg       0.58      0.61      0.59     22800\n",
            "weighted avg       0.78      0.73      0.75     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.28353713 1.        ]\n",
            "k fold false_positive_rate: [0.        0.1197179 1.       ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.80      0.84     19089\n",
            "           1       0.29      0.43      0.35      3710\n",
            "\n",
            "    accuracy                           0.74     22799\n",
            "   macro avg       0.59      0.61      0.59     22799\n",
            "weighted avg       0.78      0.74      0.76     22799\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.        0.2931066 1.       ]\n",
            "k fold false_positive_rate: [0.         0.12158107 1.        ]\n",
            "test:  [0.73109649 0.73785088 0.73495614 0.73258772 0.73801483]\n",
            "F1_Score:  [0.73109649 0.73785088 0.73495614 0.73258772 0.73801483]\n",
            "Recal_Score:  [0.28655387 0.28403968 0.283012   0.28353713 0.2931066 ]\n",
            "Train_ACC:  [0.81689492 0.81629185 0.81758572 0.81606158 0.81455044]\n",
            "Precision_Score:  [0.4309052  0.43969849 0.42548537 0.4378763  0.43207547]\n",
            "KNeighborsClassifier()\n",
            "mean Test_ACC:  0.7349012106563615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.75     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.75      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.76     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.76      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.76     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.76      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.75     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.75      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22799\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.76     22799\n",
            "   macro avg       0.50      0.38      0.43     22799\n",
            "weighted avg       1.00      0.76      0.86     22799\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n",
            "test:  [0.75372807 0.75679825 0.75885965 0.7525     0.76012106]\n",
            "F1_Score:  [0.75372807 0.75679825 0.75885965 0.7525     0.76012106]\n",
            "Recal_Score:  [0. 0. 0. 0. 0.]\n",
            "Train_ACC:  [0.7570697  0.75630215 0.7557868  0.75737673 0.75547149]\n",
            "Precision_Score:  [0. 0. 0. 0. 0.]\n",
            "LogisticRegression()\n",
            "mean Test_ACC:  0.7564014045706837\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.77      0.87     21775\n",
            "           1       0.13      0.69      0.21      1025\n",
            "\n",
            "    accuracy                           0.77     22800\n",
            "   macro avg       0.55      0.73      0.54     22800\n",
            "weighted avg       0.94      0.77      0.84     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.12626892 1.        ]\n",
            "k fold false_positive_rate: [0.         0.01838813 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87     21647\n",
            "           1       0.14      0.66      0.23      1153\n",
            "\n",
            "    accuracy                           0.77     22800\n",
            "   macro avg       0.56      0.72      0.55     22800\n",
            "weighted avg       0.93      0.77      0.83     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.13651939 1.        ]\n",
            "k fold false_positive_rate: [0.         0.02294987 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87     21666\n",
            "           1       0.13      0.65      0.22      1134\n",
            "\n",
            "    accuracy                           0.77     22800\n",
            "   macro avg       0.55      0.71      0.54     22800\n",
            "weighted avg       0.93      0.77      0.84     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.13313932 1.        ]\n",
            "k fold false_positive_rate: [0.         0.02323431 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.77      0.86     21792\n",
            "           1       0.12      0.68      0.21      1008\n",
            "\n",
            "    accuracy                           0.77     22800\n",
            "   macro avg       0.55      0.73      0.54     22800\n",
            "weighted avg       0.94      0.77      0.84     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.12121212 1.        ]\n",
            "k fold false_positive_rate: [0.         0.01888442 1.        ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87     21623\n",
            "           1       0.14      0.66      0.23      1176\n",
            "\n",
            "    accuracy                           0.78     22799\n",
            "   macro avg       0.56      0.72      0.55     22799\n",
            "weighted avg       0.93      0.78      0.84     22799\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.14225635 1.        ]\n",
            "k fold false_positive_rate: [0.         0.02296595 1.        ]\n",
            "test:  [0.77096491 0.77263158 0.77333333 0.76828947 0.77678846]\n",
            "F1_Score:  [0.77096491 0.77263158 0.77333333 0.76828947 0.77678846]\n",
            "Recal_Score:  [0.12626892 0.13651939 0.13313932 0.12121212 0.14225635]\n",
            "Train_ACC:  [0.79674119 0.8000307  0.80303512 0.79817761 0.80059211]\n",
            "Precision_Score:  [0.69170732 0.65654814 0.64550265 0.67857143 0.66156463]\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, random_state=None, ...)\n",
            "mean Test_ACC:  0.7724015507759268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.75     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.75      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.76     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.76      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.89      0.05       488\n",
            "           1       0.99      0.24      0.39     22312\n",
            "\n",
            "    accuracy                           0.26     22800\n",
            "   macro avg       0.51      0.57      0.22     22800\n",
            "weighted avg       0.97      0.26      0.38     22800\n",
            "\n",
            "false_positive_rate len:  3\n",
            "k fold true_positive_rate: [0.         0.99017825 1.        ]\n",
            "k fold false_positive_rate: [0.         0.97491619 1.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86     22800\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.75     22800\n",
            "   macro avg       0.50      0.38      0.43     22800\n",
            "weighted avg       1.00      0.75      0.86     22800\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22799\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.76     22799\n",
            "   macro avg       0.50      0.38      0.43     22799\n",
            "weighted avg       1.00      0.76      0.86     22799\n",
            "\n",
            "false_positive_rate len:  2\n",
            "k fold true_positive_rate: [0. 1.]\n",
            "k fold false_positive_rate: [0. 1.]\n",
            "1\n",
            "1\n",
            "test:  [0.75372807 0.75679825 0.25780702 0.7525     0.76012106]\n",
            "F1_Score:  [0.75372807 0.75679825 0.25780702 0.7525     0.76012106]\n",
            "Recal_Score:  [0.         0.         0.99017825 0.         0.        ]\n",
            "Train_ACC:  [0.7570697  0.75630215 0.26093488 0.75737673 0.75547149]\n",
            "Precision_Score:  [0.         0.         0.24399426 0.         0.        ]\n",
            "LinearSVC()\n",
            "mean Test_ACC:  0.6561908782548942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}